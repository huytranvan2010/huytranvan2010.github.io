---
layout: post
title: "TF-IDF"
tags: [GANs]
comments: true
---

TF-IDF là viết tắt của Term frequencey inverse document frequency. Nó có thể được xác định là mức độ liên quan của một từ trong chuỗi các đoạn text.
- **Term frequency**: trong document d, frequency (tần số) biểu diễn số lần xuất hiện của từ t. Trọng số của từ xuất hiện trong document 

$$ tf(t, d) = \frac{\text{count of t in d}}{\text{number of words in d}}$$

- **Document frequency** Ở đây chúng ta sẽ xét đến corpus (tập hợp của nhiều documents). Ở đây chúng ta quan tâm đến số lần xuất hiện của từ trong corpus.

$$df(t) = \text{occurence of t in documents}$$

- **Inverse Document Frequency**
- **Computation**: Tf-idf là một trong những metric tốt nhất để xác định độ quan trọng của từ trong một đoạn text (document) trong một corpus. tf-idf là hệ thống trọng số cái mà gán trọng số cho mỗi từ trong document dựa trên *term frequency (tf)* và *document frequency (idf)*. Từ có weight cao hơn sẽ có ý nghĩa nhiều hơn.

Thông thường tf-idf weight chứa 2 thành phần:
- Normalized term frequency (tf)
- Inverse document frequency (idf)

$$\text{tf-idf}(t, d) = \text{tf}(t, d) * \text{idf}(t)$$

Trong Python giá trị tf-idf có thể được tính bằng cách sử dụng `TfidfVectorizer()` method trong scikit-learn.

https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency/

https://viblo.asia/p/tf-idf-algorithm-text-retrieval-and-search-engines-1Je5EmGY5nL 

https://bktranquangchung.wordpress.com/2018/09/10/tf-idf/

**TF-IDF** (term frequency-inverse document frequency) là trọng số của một từ trong một văn bản thông qua thống kê 


**TF (Term frequency)** - tần suất xuất hiện của một từ trong document.

$$ tf(t, d) = \frac{\text{count of t in d}}{\text{number of words in d}}
$$

Nói cách khác $tf(t, d)$ chính là tỉ số giữa số lần xuất hiện của từ $t$ trong văn bản $d$ so với độ dài của văn bản $d$.

**Chú ý:** 
- $d$: kí hiệu cho một văn bản
- $D$: kí hiệu cho corpus hay tập các văn bản.


```python
def tf(term, doc):
    result = 0
    for word in doc:
        if word == term:
            result += 1
    return result / len(doc)
```
Ở đây `doc` thường là list các words ở trong văn bản `doc`.

**IDF (invert document frequency)** dùng để đánh giá múc độ quan trọng của 1 từ trong băn bản. Khi tính tf mức độ quan trọng của các từ coi là như nhau. Tuy nhiên trong văn bản thường xuất hiện nhiều từ không quan trọng xuất hiện với tần suất cao:
- Từ nối: và, hoặc,... (đối với tiếng Việt)
- Giới từ: ở, trong, của, để...
- Từ chỉ định: ấy, đó, nhỉ

Do đó chúng ta cần giảm mức độ quan trọng của những từ đó bằng **IDF**.

$$idf(t, D) = \log\frac{|D|}{|{d \in D: t \in d}|}$$
trong đó: 
- $|D|$ - tổng số văn bản trong corpus D (gồm nhiều văn bản)
- $|{d \in D: t \in d}|$ - số văn bản chứa từ $t$ trong corpus D

```python
# docs ở đây chính là corpus gồm nhiều doc
def idf(term, docs):
	result = 0
	for doc in docs:
		# for word in doc:
		# 	if word == term:
		# 		result += 1
		# 		break	# thoát vòng for bên trong
		# vòng for trong có thể thay bằng kiểm tra
		if word in doc:
			result += 1
	return math.log(len(docs) / result)		# ở đây lấy logarit tự nhiên thôi
```

**TF-IDF**

$$\text{TF-IDF}(t, d, D) = TF(t, d) \times IDF(t, D)$$

Những từ có giá trị TD-IDF cao (gán với văn bản $d$ và corpus $D) là những từ 
- xuất hiện nhiều trong văn bản $d$ (tương ứng $tf(t, d)$ cao) 
- và xuất hiện ít trong các văn (tương ứng với $idf(t, D)$ cao).

Chính điều này giúp lọc ra những từ phổ biến và giữ lại những giá trị cao (coi là từ khóa của văn bản). Phương pháp này có thể được sử dụng trong tìm kiếm văn bản.

**TF-IDF vectorization**

Tương tự như Bag of Word chúng ta dùng TF-iDF vectorization để biểu diễn mỗi document dưới dạng vector. Ở đây ta sẽ gán giá trị tf-idf của mỗi từ tương ứng với vị trí của nó trong document $d$ (Bag of Words sẽ thay số lần xuất hiện của từ đó trong document $d$).

**Similarity**

Các documents trong corpus được vector hóa (ví dụ bằng tf-idf vectorization) rồi lưu vào database. Những truy vấn người dùng nhập vào gọi là query, chúng cũng được chuyển về vector nhờ tf-idf vectorization hay Bag of words chảng hạn. Lúc này chúng ta có thể xác định **similarity** giữa vector của câu query và các document dựa trên feature vector. Lúc này chúng ta sê trả về document nào có similarity lớn nhất hoặc thứ tự các documents theo silimarity giảm dần chẳng hạn.

Similarity giữa hai vector thường dùng là *cosine similarity*:

$$
\text{sim}(\vec{a}, \vec{b})
$$


https://viblo.asia/p/doi-net-ve-tf-idf-trong-xu-ly-ngon-ngu-tu-nhien-vyDZO0e9lwj
https://viblo.asia/p/tf-idf-term-frequency-inverse-document-frequency-JQVkVZgKkyd

https://en.wikipedia.org/wiki/Tf%E2%80%93idf

https://viblo.asia/p/tf-idf-algorithm-text-retrieval-and-search-engines-1Je5EmGY5nL
